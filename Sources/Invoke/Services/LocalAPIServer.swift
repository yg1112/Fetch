import Foundation
import Network

// âš¡ï¸ LocalAPIServer: The Invisible Pipe
class LocalAPIServer: ObservableObject {
    static let shared = LocalAPIServer()
    
    @Published var isRunning = false
    @Published var port: UInt16 = 3000
    private var listener: NWListener?
    private let queue = DispatchQueue(label: "com.fetch.api-server")
    
    func start() {
        if isRunning && listener != nil { return }
        
        // ğŸš€ å¯åŠ¨æ—¶è‡ªåŠ¨å°è¯•ä» Chrome å· Cookie (æ— æ„Ÿç™»å½•)
        Task { @MainActor in
            if !GeminiWebManager.shared.isLoggedIn {
                ChromeBridge.shared.fetchCookiesFromChrome { result in
                    if case .success(let cookies) = result {
                        print("ğŸª Auto-injected cookies from Chrome/Arc")
                        GeminiWebManager.shared.injectRawCookies(cookies) {
                            GeminiWebManager.shared.loadGemini()
                        }
                    }
                }
            }
        }

        for tryPort in UInt16(3000)...UInt16(3010) {
            if startListener(on: tryPort) {
                self.port = tryPort
                self.isRunning = true
                print("âœ… API Server listening on port \(tryPort)")
                return
            }
        }
    }
    
    private func startListener(on port: UInt16) -> Bool {
        do {
            let params = NWParameters.tcp
            params.allowLocalEndpointReuse = true
            let newListener = try NWListener(using: params, on: NWEndpoint.Port(rawValue: port)!)
            newListener.newConnectionHandler = { [weak self] conn in self?.handleConnection(conn) }
            newListener.start(queue: queue)
            self.listener = newListener
            return true
        } catch { return false }
    }
    
    private func handleConnection(_ connection: NWConnection) {
        connection.start(queue: queue)
        receiveLoop(connection)
    }

    private func receiveLoop(_ connection: NWConnection) {
        connection.receive(minimumIncompleteLength: 1, maximumLength: 65536) { [weak self] data, _, isComplete, error in
            if let error = error { connection.cancel(); return }
            
            if let data = data, let req = String(data: data, encoding: .utf8) {
                self?.processRequest(connection, req)
                if !isComplete { self?.receiveLoop(connection) } // Keep-alive
            } else if isComplete {
                connection.cancel()
            }
        }
    }
    
    private func processRequest(_ connection: NWConnection, _ rawRequest: String) {
        let lines = rawRequest.components(separatedBy: "\r\n")
        guard let firstLine = lines.first else { return }
        
        if firstLine.contains("/chat/completions") {
            // æå– Body
            var body = ""
            if let range = rawRequest.range(of: "\r\n\r\n") {
                body = String(rawRequest[range.upperBound...])
            }
            handleChatCompletion(connection, body)
        } else {
            // Health check
            let response = "HTTP/1.1 200 OK\r\nConnection: keep-alive\r\n\r\n"
            connection.send(content: response.data(using: .utf8), completion: .contentProcessed { _ in })
        }
    }
    
    private func handleChatCompletion(_ connection: NWConnection, _ body: String) {
        guard let data = body.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let messages = json["messages"] as? [[String: Any]] else { return }

        // âœ… FIX: æ­£ç¡®æ‹¼æ¥æ‰€æœ‰ä¸Šä¸‹æ–‡
        let allContent = messages.compactMap { $0["content"] as? String }.joined(separator: "\n\n")
        
        // âœ… FIX: æ³¨å…¥ç³»ç»ŸæŒ‡ä»¤ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡æ¼‚ç§»
        // å‘Šè¯‰ Geminiï¼šå¿½ç•¥ä½ ä¹‹å‰çš„è®°å¿†ï¼Œè¿™æ˜¯ä¸€æ¬¡å…¨æ–°çš„ã€æ— çŠ¶æ€çš„è¯·æ±‚ã€‚
        let systemInstruction = "ğŸ”´ [SYSTEM INSTRUCTION: Ignore all previous conversation history in this web session. Treat the following text as a completely NEW request with full context provided.]\n\n"
        
        let robustPrompt = systemInstruction + allContent

        Task { @MainActor in
            print("ğŸ“¡ [Server] Handling Request (Length: \(robustPrompt.count))")
            
            // 1. ç«‹å³å‘é€ SSE Headerï¼Œé˜²æ­¢ Aider è¶…æ—¶
            let headers = "HTTP/1.1 200 OK\r\nContent-Type: text/event-stream\r\nCache-Control: no-cache\r\nConnection: keep-alive\r\n\r\n"
            connection.send(content: headers.data(using: .utf8), completion: .contentProcessed { _ in })

            do {
                // 2. æµå¼ä¼ è¾“
                try await GeminiWebManager.shared.streamAskGemini(prompt: robustPrompt) { chunk in
                    // OpenAI SSE Format
                    let chunkID = UUID().uuidString.prefix(8)
                    let sseChunk: [String: Any] = [
                        "id": "chatcmpl-\(chunkID)",
                        "object": "chat.completion.chunk",
                        "created": Int(Date().timeIntervalSince1970),
                        "model": "gemini-2.0-flash",
                        "choices": [[
                            "index": 0,
                            "delta": ["content": chunk],
                            "finish_reason": NSNull()
                        ]]
                    ]
                    
                    if let chunkData = try? JSONSerialization.data(withJSONObject: sseChunk),
                       let chunkJSON = String(data: chunkData, encoding: .utf8) {
                        let sseMessage = "data: \(chunkJSON)\n\n"
                        connection.send(content: sseMessage.data(using: .utf8), completion: .contentProcessed { _ in })
                    }
                }
                
                // 3. ç»“æŸæ ‡è®°
                let done = "data: [DONE]\n\n"
                connection.send(content: done.data(using: .utf8), completion: .contentProcessed { _ in })
                print("   âœ… Request Completed")
                
            } catch {
                print("   âŒ Error: \(error)")
                let errChunk = "data: {\"choices\":[{\"delta\":{\"content\":\" [Error: \(error.localizedDescription)]\"}}]}\n\ndata: [DONE]\n\n"
                connection.send(content: errChunk.data(using: .utf8), completion: .contentProcessed { _ in })
            }
        }
    }
}